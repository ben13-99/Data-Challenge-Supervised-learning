{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import log_loss, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import log_loss, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--- \n",
    "Data cleaning \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train_data.csv\")\n",
    "data_test = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_year</th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>arrival_date_day_of_month</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>adults</th>\n",
       "      <th>children</th>\n",
       "      <th>...</th>\n",
       "      <th>reserved_room_type</th>\n",
       "      <th>assigned_room_type</th>\n",
       "      <th>booking_changes</th>\n",
       "      <th>deposit_type</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>335</td>\n",
       "      <td>2017</td>\n",
       "      <td>June</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>74.25</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>68898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City Hotel</td>\n",
       "      <td>71</td>\n",
       "      <td>2016</td>\n",
       "      <td>June</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>Non Refund</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>120.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>207</td>\n",
       "      <td>2017</td>\n",
       "      <td>May</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>117.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>68900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>City Hotel</td>\n",
       "      <td>109</td>\n",
       "      <td>2016</td>\n",
       "      <td>August</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>108.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>68901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>City Hotel</td>\n",
       "      <td>28</td>\n",
       "      <td>2017</td>\n",
       "      <td>April</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>116.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          hotel  lead_time  arrival_date_year arrival_date_month  \\\n",
       "0  Resort Hotel        335               2017               June   \n",
       "1    City Hotel         71               2016               June   \n",
       "2  Resort Hotel        207               2017                May   \n",
       "3    City Hotel        109               2016             August   \n",
       "4    City Hotel         28               2017              April   \n",
       "\n",
       "   arrival_date_week_number  arrival_date_day_of_month  \\\n",
       "0                        26                         26   \n",
       "1                        25                         14   \n",
       "2                        20                         19   \n",
       "3                        33                          8   \n",
       "4                        17                         27   \n",
       "\n",
       "   stays_in_weekend_nights  stays_in_week_nights  adults  children  ...  \\\n",
       "0                        1                     3       2       0.0  ...   \n",
       "1                        0                     3       1       0.0  ...   \n",
       "2                        2                     2       2       0.0  ...   \n",
       "3                        2                     5       1       0.0  ...   \n",
       "4                        0                     2       2       0.0  ...   \n",
       "\n",
       "   reserved_room_type assigned_room_type booking_changes deposit_type  \\\n",
       "0                   A                  A               0   No Deposit   \n",
       "1                   A                  A               0   Non Refund   \n",
       "2                   D                  D               2   No Deposit   \n",
       "3                   A                  A               0   No Deposit   \n",
       "4                   A                  A               0   No Deposit   \n",
       "\n",
       "  days_in_waiting_list  customer_type     adr  required_car_parking_spaces  \\\n",
       "0                    0      Transient   74.25                            0   \n",
       "1                    0      Transient  120.00                            0   \n",
       "2                    0      Transient  117.00                            0   \n",
       "3                    0      Transient  108.90                            0   \n",
       "4                    0      Transient  116.20                            0   \n",
       "\n",
       "  total_of_special_requests row_id  \n",
       "0                         2  68898  \n",
       "1                         0  68899  \n",
       "2                         1  68900  \n",
       "3                         1  68901  \n",
       "4                         0  68902  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.iloc[:, 1:-1]\n",
    "data_test = data_test.iloc[:, 1: ]\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_year</th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>arrival_date_day_of_month</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>adults</th>\n",
       "      <th>children</th>\n",
       "      <th>...</th>\n",
       "      <th>reserved_room_type</th>\n",
       "      <th>assigned_room_type</th>\n",
       "      <th>booking_changes</th>\n",
       "      <th>deposit_type</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>reservation_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City Hotel</td>\n",
       "      <td>47</td>\n",
       "      <td>2016</td>\n",
       "      <td>March</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>85.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>221</td>\n",
       "      <td>2017</td>\n",
       "      <td>April</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient-Party</td>\n",
       "      <td>71.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>City Hotel</td>\n",
       "      <td>11</td>\n",
       "      <td>2016</td>\n",
       "      <td>February</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>79.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>88</td>\n",
       "      <td>2015</td>\n",
       "      <td>November</td>\n",
       "      <td>48</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>32.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>250</td>\n",
       "      <td>2017</td>\n",
       "      <td>August</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>106.85</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          hotel  lead_time  arrival_date_year arrival_date_month  \\\n",
       "0    City Hotel         47               2016              March   \n",
       "1  Resort Hotel        221               2017              April   \n",
       "2    City Hotel         11               2016           February   \n",
       "3  Resort Hotel         88               2015           November   \n",
       "4  Resort Hotel        250               2017             August   \n",
       "\n",
       "   arrival_date_week_number  arrival_date_day_of_month  \\\n",
       "0                        13                         20   \n",
       "1                        18                         30   \n",
       "2                         6                          1   \n",
       "3                        48                         28   \n",
       "4                        33                         13   \n",
       "\n",
       "   stays_in_weekend_nights  stays_in_week_nights  adults  children  ...  \\\n",
       "0                        2                     2       2       0.0  ...   \n",
       "1                        2                     5       2       0.0  ...   \n",
       "2                        2                     5       2       0.0  ...   \n",
       "3                        2                     4       2       0.0  ...   \n",
       "4                        2                     2       2       0.0  ...   \n",
       "\n",
       "   reserved_room_type assigned_room_type booking_changes deposit_type  \\\n",
       "0                   A                  D               0   No Deposit   \n",
       "1                   A                  A               0   No Deposit   \n",
       "2                   A                  A               0   No Deposit   \n",
       "3                   A                  A               0   No Deposit   \n",
       "4                   A                  A               1   No Deposit   \n",
       "\n",
       "  days_in_waiting_list    customer_type     adr  required_car_parking_spaces  \\\n",
       "0                    0        Transient   85.00                            0   \n",
       "1                    0  Transient-Party   71.43                            0   \n",
       "2                    0        Transient   79.00                            0   \n",
       "3                    0        Transient   32.40                            0   \n",
       "4                    0        Transient  106.85                            0   \n",
       "\n",
       "  total_of_special_requests reservation_status  \n",
       "0                         0                  2  \n",
       "1                         0                  1  \n",
       "2                         0                  1  \n",
       "3                         0                  1  \n",
       "4                         1                  0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bis = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_year</th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>arrival_date_day_of_month</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>adults</th>\n",
       "      <th>children</th>\n",
       "      <th>...</th>\n",
       "      <th>reserved_room_type</th>\n",
       "      <th>assigned_room_type</th>\n",
       "      <th>booking_changes</th>\n",
       "      <th>deposit_type</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>335</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>74.25</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>68898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City Hotel</td>\n",
       "      <td>71</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>Non Refund</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>120.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>207</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>117.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>68900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>City Hotel</td>\n",
       "      <td>109</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>108.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>68901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>City Hotel</td>\n",
       "      <td>28</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>116.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          hotel  lead_time  arrival_date_year  arrival_date_month  \\\n",
       "0  Resort Hotel        335               2017                   6   \n",
       "1    City Hotel         71               2016                   6   \n",
       "2  Resort Hotel        207               2017                   5   \n",
       "3    City Hotel        109               2016                   8   \n",
       "4    City Hotel         28               2017                   4   \n",
       "\n",
       "   arrival_date_week_number  arrival_date_day_of_month  \\\n",
       "0                        26                         26   \n",
       "1                        25                         14   \n",
       "2                        20                         19   \n",
       "3                        33                          8   \n",
       "4                        17                         27   \n",
       "\n",
       "   stays_in_weekend_nights  stays_in_week_nights  adults  children  ...  \\\n",
       "0                        1                     3       2       0.0  ...   \n",
       "1                        0                     3       1       0.0  ...   \n",
       "2                        2                     2       2       0.0  ...   \n",
       "3                        2                     5       1       0.0  ...   \n",
       "4                        0                     2       2       0.0  ...   \n",
       "\n",
       "   reserved_room_type assigned_room_type booking_changes deposit_type  \\\n",
       "0                   A                  A               0   No Deposit   \n",
       "1                   A                  A               0   Non Refund   \n",
       "2                   D                  D               2   No Deposit   \n",
       "3                   A                  A               0   No Deposit   \n",
       "4                   A                  A               0   No Deposit   \n",
       "\n",
       "  days_in_waiting_list  customer_type     adr  required_car_parking_spaces  \\\n",
       "0                    0      Transient   74.25                            0   \n",
       "1                    0      Transient  120.00                            0   \n",
       "2                    0      Transient  117.00                            0   \n",
       "3                    0      Transient  108.90                            0   \n",
       "4                    0      Transient  116.20                            0   \n",
       "\n",
       "  total_of_special_requests row_id  \n",
       "0                         2  68898  \n",
       "1                         0  68899  \n",
       "2                         1  68900  \n",
       "3                         1  68901  \n",
       "4                         0  68902  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bis['arrival_date_month'] = pd.to_datetime(data_bis['arrival_date_month'], format = '%B').dt.month\n",
    "data_test['arrival_date_month'] =  pd.to_datetime(data_test['arrival_date_month'], format = '%B').dt.month\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test.drop(columns=['row_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the columns to be processed by the previous pre-processing\n",
    "non_numeric = data_bis.select_dtypes(exclude='number').columns\n",
    "transform = [c for c in non_numeric if data_bis[c].unique().shape[0] >= 3]\n",
    "\n",
    "### Get the columns to be one-hot encoded \n",
    "one_hot = [c for c in non_numeric if data_bis[c].unique().shape[0] < 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Hard to find any significant correlation with regards to the numerical values. We clearly see that the categorial variables are really significant here.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  First strategy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "Description:\n",
    "--- \n",
    "\n",
    "**Pipeline**: \n",
    "\n",
    "\n",
    "- Replace categorial data with certain statistial behaviour by the vector : (Pr(reservation status = 0 | country), Pr(reservation status = 1 | country), Pr(reservation status = 2 | country) smoothed out.\n",
    "- Standard scaler for numerical values.\n",
    "- Custom loss taking into account that predicting *check_out* and having *no_show* is something to be more penalized\n",
    "  than any other error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data_bis, train_size=0.8, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55118, 28), (13780, 28))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Data Transformation:\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "In the next sections, the following transformation will be applied to our data:\n",
    "\n",
    "Let $X$ a categorical column which takes values in $\\{x_1,...,x_p\\}$ such that $p \\ge 3$. If $X[i]$ is the value of $X$ at the row $i$, we\n",
    "compute an estimate of the following probabilities:\n",
    "\n",
    "$$\n",
    "\\hat{X}_{\\text{check_out}}[i] = \\hat{\\mathbb{P}}(\\text{check_out} | X = X[i])\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{X}_{\\text{cancel}}[i] = \\hat{\\mathbb{P}}(\\text{cancel} | X = X[i])\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{X}_{\\text{no_show}}[i] = \\hat{\\mathbb{P}}(\\text{no_show} | X = X[i])\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{n}[i] = \\sum_{j = 1}^N \\mathbb{1}_{X[j] = X[i]}\n",
    "$$\n",
    "\n",
    "\n",
    "One can replace the column $X$ by the column $\\hat{X}_{\\text{check_out}}, \\hat{X}_{\\text{cancel}}, \\hat{X}_{\\text{no_show}}, \\hat{n}$\n",
    "\n",
    "\n",
    "---\n",
    "Advantages:\n",
    "\n",
    "- Avoid one hot encoding where there are more than 3 different values that could be taken by a column\n",
    "- Capture information related to the probability of an outcome knowing the value of the column\n",
    "- Facilitate the learning : instead of heavily relying on the model to capture information, the features are added consciously\n",
    "---\n",
    "Drawbacks:\n",
    "\n",
    "- Since there are some categories which are over-represented, and some under-represented, there is an unbalance.\n",
    "- Relies heavily of the collected data, which means that a bias is likely to appear.\n",
    "---\n",
    "Find a compromise:\n",
    "\n",
    "Compute the following estimate:\n",
    "\n",
    "$$\n",
    "\\hat{p}_{\\text{check_out}} = \\hat{\\mathbb{P}}(\\text{check_out})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{p}_{\\text{cancel}} = \\hat{\\mathbb{P}}(\\text{cancel})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{p}_{\\text{no_show}} = \\hat{\\mathbb{P}}(\\text{no_show})\n",
    "$$\n",
    "\n",
    "Then transform data in the following way:\n",
    "\n",
    "Let $X[j]$ for value of $X$ in the $j^{th}$ row, we update the follwing rows\n",
    "\n",
    "$$\n",
    "\\hat{X}_{\\text{check_out}}[j] \\leftarrow \\frac{n[j] \\times \\hat{X}_{\\text{check_out}}[j] + K \\times \\hat{p}_{\\text{check_out}}}{n[j] + K}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{X}_{\\text{cance}}[j] \\leftarrow \\frac{n[j] \\times \\hat{X}_{\\text{cancel}}[j] + K \\times \\hat{p}_{\\text{cancel}}}{n[j] + K}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{X}_{\\text{no_show}}[j] \\leftarrow \\frac{n[j] \\times \\hat{X}_{\\text{no_show}}[j] + K \\times \\hat{p}_{\\text{no_show}}}{n[j] + K}\n",
    "$$\n",
    "\n",
    "Where $K$ is a smothing hyper-parameter\n",
    " \n",
    "---\n",
    "\n",
    "For the categorical variables having unique values less or equal to two should be one-hot encoded.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the columns to be processed by the previous pre-processing\n",
    "non_numeric = data_bis.select_dtypes(exclude='number').columns\n",
    "transform = [c for c in non_numeric if data_bis[c].unique().shape[0] >= 3]\n",
    "\n",
    "### Get the columns to be one-hot encoded \n",
    "one_hot = [c for c in non_numeric if data_bis[c].unique().shape[0] < 3]\n",
    "\n",
    "train_df = pd.get_dummies(train_df, columns = one_hot, drop_first=True, dtype=int)\n",
    "test_df = pd.get_dummies(test_df, columns = one_hot, drop_first=True, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing of the *transform* columns:\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Create a Cross-Validation dataset *folds* from *train_df* on which we train multiple models on train datasets\n",
    "and tune an expert aggregation on the validation sets.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "num_classes = train_df['reservation_status'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "folds = []\n",
    "for train_idx, val_idx in kf.split(train_df, train_df['reservation_status']):\n",
    "    ### Split folds:\n",
    "    t = train_df.iloc[train_idx].copy()\n",
    "    s = train_df.iloc[val_idx].copy()\n",
    "    u = test_df.copy()\n",
    "    \n",
    "    \n",
    "    ### Get global variables:\n",
    "    g_probs = pd.DataFrame(t['reservation_status'].value_counts(normalize = True).reset_index())\n",
    "\n",
    "\n",
    "    for k in range(len(transform)):\n",
    "    \n",
    "        c = transform[k] \n",
    "\n",
    "        ### first phase: compute conditional probabilities and n\n",
    "        probs = t.groupby(c)['reservation_status'].value_counts(normalize = True).unstack().reset_index()\n",
    "        probs = probs.fillna(0)\n",
    "        cols = [f'{c}_{col}' for col in probs.columns if col != c]\n",
    "        cols = [c] + cols\n",
    "\n",
    "        probs = probs.merge(pd.DataFrame(t.groupby(c).size()), on = c, how = 'left')\n",
    "        probs.columns = cols + [f'{c}_count']\n",
    "\n",
    "        \n",
    "\n",
    "        ### second phase : smothed probabilities:\n",
    "        for j in t['reservation_status'].unique():\n",
    "            gp = g_probs.loc[(g_probs['reservation_status'] == j), 'proportion'].values[0]\n",
    "            probs[f'{c}_{j}'] = (probs[f'{c}_{j}'] * probs[f'{c}_count'] +  gp * K) / (probs[f'{c}_count'] + K)\n",
    "        \n",
    "\n",
    "        probs = probs.drop(f'{c}_count', axis = 1)\n",
    "        \n",
    "\n",
    "        t = t.merge(probs, on = c, how = 'left')\n",
    "        t = t.drop(c, axis = 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # merge into val fold\n",
    "        s = s.merge(probs, on=c, how='left')\n",
    "        for j in t['reservation_status'].unique():\n",
    "            gp = g_probs.loc[g_probs['reservation_status']==j, 'proportion'].values[0]\n",
    "            s[f'{c}_{j}'] = s[f'{c}_{j}'].fillna(gp)\n",
    "        s = s.drop(c, axis = 1)\n",
    "        \n",
    "        \n",
    "        u = u.merge(probs, on = c, how = 'left')\n",
    "        for j in t['reservation_status'].unique():\n",
    "            gp = g_probs.loc[g_probs['reservation_status']==j, 'proportion'].values[0]\n",
    "            u[f'{c}_{j}'] = u[f'{c}_{j}'].fillna(gp)\n",
    "        u = u.drop(c, axis = 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    # Prepare X, y\n",
    "    y_train = t['reservation_status']\n",
    "    X_train = t.drop(columns=['reservation_status'])\n",
    "    y_val = s['reservation_status']\n",
    "    X_val = s.drop(columns=['reservation_status'])\n",
    "    y_test = u['reservation_status']\n",
    "    X_test = u.drop(columns = 'reservation_status')\n",
    "    \n",
    "    \n",
    "    # Scale numeric features for linear models\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    folds.append(\n",
    "        (X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === More diverse base models ===\n",
    "# models = {\n",
    "#     \"fast_rf\" : HistGradientBoostingClassifier(max_depth=8, learning_rate=0.1, max_iter=200, random_state=42),\n",
    "#     \"RandomForest\": RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
    "#     \"ExtraTrees\": ExtraTreesClassifier(n_estimators=200, max_depth=10, random_state=42),\n",
    "#     \"LogisticRegression\": LogisticRegression(max_iter=1000, multi_class='multinomial', random_state=42),\n",
    "#     \"GradientBoosting\": GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=42),\n",
    "#     \"LightGBM\": LGBMClassifier(n_estimators=200, num_leaves=31, learning_rate=0.1, random_state=42),\n",
    "#     \"CatBoost\": CatBoostClassifier(n_estimators=200, depth=6, learning_rate=0.1, verbose=0, random_state=42)\n",
    "\n",
    "# }\n",
    "\n",
    "models = {\n",
    "    \"fast_rf\" : HistGradientBoostingClassifier(max_depth=8, learning_rate=0.1, max_iter=200, random_state=42),\n",
    "    \"ExtraTrees\": ExtraTreesClassifier(n_estimators=200, max_depth=10, random_state=42),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000, multi_class='multinomial', random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(n_estimators=200, depth=6, learning_rate=0.1, verbose=0, random_state=42)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Learning phase:\n",
    "---\n",
    "\n",
    "Train each model of the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "fast_rf: Fold log-loss = 0.3124\n",
      "ExtraTrees: Fold log-loss = 0.4331\n",
      "LogisticRegression: Fold log-loss = 0.4244\n",
      "RandomForest: Fold log-loss = 0.3750\n",
      "CatBoost: Fold log-loss = 0.3338\n",
      "\n",
      "=== Fold 2 ===\n",
      "fast_rf: Fold log-loss = 0.3159\n",
      "ExtraTrees: Fold log-loss = 0.4346\n",
      "LogisticRegression: Fold log-loss = 0.4310\n",
      "RandomForest: Fold log-loss = 0.3759\n",
      "CatBoost: Fold log-loss = 0.3371\n",
      "\n",
      "=== Fold 3 ===\n",
      "fast_rf: Fold log-loss = 0.3139\n",
      "ExtraTrees: Fold log-loss = 0.4331\n",
      "LogisticRegression: Fold log-loss = 0.4276\n",
      "RandomForest: Fold log-loss = 0.3762\n",
      "CatBoost: Fold log-loss = 0.3386\n",
      "\n",
      "=== Fold 4 ===\n",
      "fast_rf: Fold log-loss = 0.3167\n",
      "ExtraTrees: Fold log-loss = 0.4440\n",
      "LogisticRegression: Fold log-loss = 0.4329\n",
      "RandomForest: Fold log-loss = 0.3800\n",
      "CatBoost: Fold log-loss = 0.3383\n",
      "\n",
      "=== Fold 5 ===\n",
      "fast_rf: Fold log-loss = 0.3044\n",
      "ExtraTrees: Fold log-loss = 0.4348\n",
      "LogisticRegression: Fold log-loss = 0.4288\n",
      "RandomForest: Fold log-loss = 0.3735\n",
      "CatBoost: Fold log-loss = 0.3293\n"
     ]
    }
   ],
   "source": [
    "# Containers\n",
    "oof_preds = {name: [] for name in models.keys()}\n",
    "oof_labels = []\n",
    "trained_models_per_fold = []\n",
    "fold_test_sets = []\n",
    "\n",
    "for fold_idx, (X_train, y_train, X_val, y_val, X_test_fold, y_test_fold) in enumerate(folds):\n",
    "    print(f\"\\n=== Fold {fold_idx+1} ===\")\n",
    "    \n",
    "    fold_test_sets.append((X_test_fold, y_test_fold))\n",
    "    \n",
    "    trained_models = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        trained_models[name] = model\n",
    "\n",
    "        val_pred = np.clip(model.predict_proba(X_val), 1e-15, 1-1e-15)\n",
    "        oof_preds[name].append(val_pred)\n",
    "\n",
    "        print(f\"{name}: Fold log-loss = {log_loss(y_val, val_pred):.4f}\")\n",
    "        \n",
    "    trained_models_per_fold.append(trained_models)\n",
    "    oof_labels.append(y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Meta-learner: train phase\n",
    "---\n",
    "\n",
    "Train a meta-learner for an expert aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-features shape: (55118, 15)\n",
      "Meta-labels shape: (55118,)\n",
      "\n",
      "=== Training Meta-Learner ===\n",
      "\n",
      "=== Meta-Learner Performance (OOF) ===\n",
      "Log-loss: 0.2846\n",
      "Weighted F1: 0.8711\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# === Construction du jeu méta ===\n",
    "# On empile les prédictions OOF (une par modèle de base)\n",
    "meta_features = []\n",
    "\n",
    "for name, preds_list in oof_preds.items():\n",
    "    # Concatène les folds verticalement\n",
    "    stacked_preds = np.vstack(preds_list)\n",
    "    \n",
    "    # Renomme les colonnes pour garder une trace du modèle et de la classe\n",
    "    cols = [f\"{name}_class{i}\" for i in range(stacked_preds.shape[1])]\n",
    "    \n",
    "    meta_features.append(pd.DataFrame(stacked_preds, columns=cols))\n",
    "\n",
    "# Fusionne toutes les features OOF\n",
    "meta_X = pd.concat(meta_features, axis=1)\n",
    "\n",
    "# Les vraies étiquettes associées\n",
    "meta_y = np.concatenate(oof_labels)\n",
    "\n",
    "print(f\"Meta-features shape: {meta_X.shape}\")\n",
    "print(f\"Meta-labels shape: {meta_y.shape}\")\n",
    "\n",
    "# === Meta-learner ===\n",
    "meta_model = HistGradientBoostingClassifier(\n",
    "    max_iter=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    l2_regularization=0.1,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entraînement du meta-learner\n",
    "print(\"\\n=== Training Meta-Learner ===\")\n",
    "meta_model.fit(meta_X, meta_y)\n",
    "\n",
    "# Évaluation sur les données OOF (sur lesquelles il a été entraîné)\n",
    "meta_preds = meta_model.predict_proba(meta_X)\n",
    "meta_preds = np.clip(meta_preds, 1e-15, 1 - 1e-15)\n",
    "\n",
    "meta_logloss = log_loss(meta_y, meta_preds)\n",
    "meta_f1 = f1_score(meta_y, np.argmax(meta_preds, axis=1), average='weighted')\n",
    "\n",
    "print(f\"\\n=== Meta-Learner Performance (OOF) ===\")\n",
    "print(f\"Log-loss: {meta_logloss:.4f}\")\n",
    "print(f\"Weighted F1: {meta_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Testing phase: see how effective the aggregation:\n",
    "---\n",
    "\n",
    "Testing on the testing sets if the aggregation performed better than each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 Test Evaluation ===\n",
      "Meta-learner - Fold log-loss: 0.3320 | Weighted F1: 0.8478\n",
      "\n",
      "=== Fold 2 Test Evaluation ===\n",
      "Meta-learner - Fold log-loss: 0.3362 | Weighted F1: 0.8485\n",
      "\n",
      "=== Fold 3 Test Evaluation ===\n",
      "Meta-learner - Fold log-loss: 0.3401 | Weighted F1: 0.8465\n",
      "\n",
      "=== Fold 4 Test Evaluation ===\n",
      "Meta-learner - Fold log-loss: 0.3329 | Weighted F1: 0.8505\n",
      "\n",
      "=== Fold 5 Test Evaluation ===\n",
      "Meta-learner - Fold log-loss: 0.3084 | Weighted F1: 0.8656\n",
      "\n",
      "=== Meta-learner - Global Test Performance ===\n",
      "Log-loss: mean = 0.3299, std = 0.0111\n",
      "Weighted F1: mean = 0.8518, std = 0.0070\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# === Test final : prédiction avec le meta-learner sur les fold test sets ===\n",
    "logloss_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for fold_idx, (trained_models, (X_test_fold, y_test_fold)) in enumerate(zip(trained_models_per_fold, fold_test_sets)):\n",
    "    print(f\"\\n=== Fold {fold_idx+1} Test Evaluation ===\")\n",
    "    \n",
    "    fold_base_preds = []\n",
    "    \n",
    "    for name, model in trained_models.items():\n",
    "        preds_proba = np.clip(model.predict_proba(X_test_fold), 1e-15, 1-1e-15)\n",
    "        cols = [f\"{name}_class{i}\" for i in range(preds_proba.shape[1])]\n",
    "        fold_base_preds.append(pd.DataFrame(preds_proba, columns=cols))\n",
    "    \n",
    "    X_meta_test_fold = pd.concat(fold_base_preds, axis=1)\n",
    "    \n",
    "    test_meta_proba = meta_model.predict_proba(X_meta_test_fold)\n",
    "    test_meta_preds = np.argmax(test_meta_proba, axis=1)\n",
    "    \n",
    "    test_logloss = log_loss(y_test_fold, test_meta_proba)\n",
    "    test_f1 = f1_score(y_test_fold, test_meta_preds, average='weighted')\n",
    "    \n",
    "    logloss_scores.append(test_logloss)\n",
    "    f1_scores.append(test_f1)\n",
    "    \n",
    "    print(f\"Meta-learner - Fold log-loss: {test_logloss:.4f} | Weighted F1: {test_f1:.4f}\")\n",
    "\n",
    "# === Statistiques globales sur toutes les folds ===\n",
    "print(\"\\n=== Meta-learner - Global Test Performance ===\")\n",
    "print(f\"Log-loss: mean = {np.mean(logloss_scores):.4f}, std = {np.std(logloss_scores):.4f}\")\n",
    "print(f\"Weighted F1: mean = {np.mean(f1_scores):.4f}, std = {np.std(f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Analysis:\n",
    "---\n",
    "\n",
    "First we se that Random Forest like models perform well. So we can choose to stick only to these kind of models. Then, what is to be noticed is the fact that the aggregator trained *across* the folds, that is, an aggregator that looks at the *universal* performence of *type* of model, does better than each model separately. The idea of looking across the folds imposed itself as a necessity to reduce bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Adapt strategy to the entire dataset:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split folds:\n",
    "t = train_df.copy()\n",
    "s = test_df.copy()\n",
    "\n",
    "\n",
    "\n",
    "### Get global variables:\n",
    "g_probs = pd.DataFrame(t['reservation_status'].value_counts(normalize = True).reset_index())\n",
    "\n",
    "\n",
    "for k in range(len(transform)):\n",
    "\n",
    "    c = transform[k] \n",
    "\n",
    "    ### first phase: compute conditional probabilities and n\n",
    "    probs = t.groupby(c)['reservation_status'].value_counts(normalize = True).unstack().reset_index()\n",
    "    probs = probs.fillna(0)\n",
    "    cols = [f'{c}_{col}' for col in probs.columns if col != c]\n",
    "    cols = [c] + cols\n",
    "\n",
    "    probs = probs.merge(pd.DataFrame(t.groupby(c).size()), on = c, how = 'left')\n",
    "    probs.columns = cols + [f'{c}_count']\n",
    "\n",
    "\n",
    "\n",
    "    ### second phase : smothed probabilities:\n",
    "    for j in t['reservation_status'].unique():\n",
    "        gp = g_probs.loc[(g_probs['reservation_status'] == j), 'proportion'].values[0]\n",
    "        probs[f'{c}_{j}'] = (probs[f'{c}_{j}'] * probs[f'{c}_count'] +  gp * K) / (probs[f'{c}_count'] + K)\n",
    "\n",
    "\n",
    "    probs = probs.drop(f'{c}_count', axis = 1)\n",
    "\n",
    "\n",
    "    t = t.merge(probs, on = c, how = 'left')\n",
    "    t = t.drop(c, axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "    # merge into val fold\n",
    "    s = s.merge(probs, on=c, how='left')\n",
    "    for j in t['reservation_status'].unique():\n",
    "        gp = g_probs.loc[g_probs['reservation_status']==j, 'proportion'].values[0]\n",
    "        s[f'{c}_{j}'] = s[f'{c}_{j}'].fillna(gp)\n",
    "    s = s.drop(c, axis = 1)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prepare X, y\n",
    "y_train = t['reservation_status']\n",
    "X_train = t.drop(columns=['reservation_status'])\n",
    "y_test = s['reservation_status']\n",
    "X_test = s.drop(columns=['reservation_status'])\n",
    "\n",
    "# Scale numeric features for linear models\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models_full = {}\n",
    "meta_features_train_full = []\n",
    "\n",
    "print(\"=== Phase 1: Retrain base models on full training set ===\")\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}\")\n",
    "    model.fit(X_train_scaled, y_train)  # full training set\n",
    "    trained_models_full[name] = model\n",
    "\n",
    "    # Predictions for meta-learner (train set)\n",
    "    preds_train = np.clip(model.predict_proba(X_train_scaled), 1e-15, 1-1e-15)\n",
    "    meta_features_train_full.append(preds_train)\n",
    "\n",
    "    # === Optional: Evaluate this base model on test set ===\n",
    "    preds_test = np.clip(model.predict_proba(X_test_scaled), 1e-15, 1-1e-15)\n",
    "    preds_test_labels = np.argmax(preds_test, axis=1)\n",
    "    \n",
    "    test_logloss = log_loss(y_test, preds_test)\n",
    "    test_f1 = f1_score(y_test, preds_test_labels, average='weighted')\n",
    "    \n",
    "    print(f\"{name} - Test log-loss: {test_logloss:.4f} | F1-weighted: {test_f1:.4f}\")\n",
    "\n",
    "print(\"Phase 1 completed.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_features_test = []\n",
    "\n",
    "print(\"=== Phase 2: Predict base model probabilities on test set ===\")\n",
    "for name, model in trained_models_full.items():\n",
    "    preds_test = np.clip(model.predict_proba(X_test_scaled), 1e-15, 1-1e-15)\n",
    "    meta_features_test.append(preds_test)\n",
    "\n",
    "# Stack predictions for meta-learner\n",
    "X_meta_test = np.hstack(meta_features_test)\n",
    "\n",
    "print(\"Phase 2 completed.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Phase 3: Aggregate predictions with universal meta-learner ===\")\n",
    "\n",
    "# Use the meta-learner learned from CV\n",
    "test_meta_proba = meta_model.predict_proba(X_meta_test)\n",
    "test_meta_preds = np.argmax(test_meta_proba, axis=1)\n",
    "\n",
    "from sklearn.metrics import log_loss, f1_score\n",
    "test_logloss = log_loss(y_test, test_meta_proba)\n",
    "test_f1 = f1_score(y_test, test_meta_preds, average='weighted')\n",
    "\n",
    "print(f\"Aggregated model - Test log-loss: {test_logloss:.4f} | F1-weighted: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Without data transformation:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data_bis, train_size=0.95, random_state=13)\n",
    "y_train = train_df['reservation_status']\n",
    "X_train = train_df.drop(columns = ['reservation_status'])\n",
    "X_train = pd.get_dummies(X_train, columns=one_hot, drop_first=True, dtype=int)\n",
    "data_test = pd.get_dummies(data_test, columns=one_hot, drop_first = True, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((65453, 27), (65453,))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1722, 27), (1723, 27), (1722,), (1723,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_online, X_test = train_test_split(test_df, train_size = 0.5)\n",
    "\n",
    "y_online = X_online['reservation_status']\n",
    "X_online = X_online.drop(columns = ['reservation_status'])\n",
    "X_online = pd.get_dummies(X_online, columns=one_hot, drop_first=True, dtype=int)\n",
    "\n",
    "y_test = X_test['reservation_status']\n",
    "X_test = X_test.drop(columns = ['reservation_status'])\n",
    "X_test = pd.get_dummies(X_test, columns=one_hot, drop_first=True, dtype=int)\n",
    "\n",
    "X_online.shape, X_test.shape, y_online.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb = HistGradientBoostingClassifier(max_depth=8, learning_rate=0.1, max_iter=200, random_state=42)\n",
    "\n",
    "### Split folds:\n",
    "t = X_train.copy()\n",
    "t['reservation_status'] = y_train\n",
    "s = X_test.copy()\n",
    "u = X_online.copy()\n",
    "hb_final_test = data_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "### Get global variables:\n",
    "g_probs = pd.DataFrame(t['reservation_status'].value_counts(normalize = True).reset_index())\n",
    "\n",
    "\n",
    "for k in range(len(transform)):\n",
    "\n",
    "    c = transform[k] \n",
    "\n",
    "    ### first phase: compute conditional probabilities and n\n",
    "    probs = t.groupby(c)['reservation_status'].value_counts(normalize = True).unstack().reset_index()\n",
    "    probs = probs.fillna(0)\n",
    "    cols = [f'{c}_{col}' for col in probs.columns if col != c]\n",
    "    cols = [c] + cols\n",
    "\n",
    "    probs = probs.merge(pd.DataFrame(t.groupby(c).size()), on = c, how = 'left')\n",
    "    probs.columns = cols + [f'{c}_count']\n",
    "\n",
    "\n",
    "\n",
    "    ### second phase : smothed probabilities:\n",
    "    for j in t['reservation_status'].unique():\n",
    "        gp = g_probs.loc[(g_probs['reservation_status'] == j), 'proportion'].values[0]\n",
    "        probs[f'{c}_{j}'] = (probs[f'{c}_{j}'] * probs[f'{c}_count'] +  gp * K) / (probs[f'{c}_count'] + K)\n",
    "\n",
    "\n",
    "    probs = probs.drop(f'{c}_count', axis = 1)\n",
    "\n",
    "\n",
    "    t = t.merge(probs, on = c, how = 'left')\n",
    "    t = t.drop(c, axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "    # merge into val fold\n",
    "    s = s.merge(probs, on=c, how='left')\n",
    "    for j in t['reservation_status'].unique():\n",
    "        gp = g_probs.loc[g_probs['reservation_status']==j, 'proportion'].values[0]\n",
    "        s[f'{c}_{j}'] = s[f'{c}_{j}'].fillna(gp)\n",
    "    s = s.drop(c, axis = 1)\n",
    "\n",
    "\n",
    "    # merge into val fold\n",
    "    u = u.merge(probs, on=c, how='left')\n",
    "    for j in t['reservation_status'].unique():\n",
    "        gp = g_probs.loc[g_probs['reservation_status']==j, 'proportion'].values[0]\n",
    "        u[f'{c}_{j}'] = u[f'{c}_{j}'].fillna(gp)\n",
    "    u = u.drop(c, axis = 1)\n",
    "    \n",
    "    \n",
    "    hb_final_test = hb_final_test.merge(probs, on=c, how='left')\n",
    "    for j in t['reservation_status'].unique():\n",
    "        gp = g_probs.loc[g_probs['reservation_status']==j, 'proportion'].values[0]\n",
    "        hb_final_test[f'{c}_{j}'] = hb_final_test[f'{c}_{j}'].fillna(gp)\n",
    "    hb_final_test = hb_final_test.drop(c, axis = 1)\n",
    "    \n",
    "t = t.drop(columns = ['reservation_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histo - Test log-loss: 0.3100 | F1-weighted: 0.8620\n"
     ]
    }
   ],
   "source": [
    "name = \"Histo\"\n",
    "\n",
    "# Scale numeric features for linear models\n",
    "scaler = StandardScaler()\n",
    "hb_train = scaler.fit_transform(t)\n",
    "hb_test = scaler.transform(s)\n",
    "hb_online = scaler.transform(u)\n",
    "hb_final_test = scaler.transform(hb_final_test)\n",
    "\n",
    "\n",
    "hb.fit(hb_train, y_train)\n",
    "proba = hb.predict_proba(hb_test)\n",
    "preds = np.argmax(proba, axis=1)\n",
    "loss = log_loss(y_test, proba)\n",
    "f1 = f1_score(y_test, preds, average='weighted')\n",
    "print(f\"{name} - Test log-loss: {loss:.4f} | F1-weighted: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "CatBoost = CatBoostClassifier(verbose = 0, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt',   # classique, basé sur histogramme\n",
    "    n_estimators=100,\n",
    "    max_depth=7,\n",
    "    num_leaves=31,\n",
    "    learning_rate=0.1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meal',\n",
       " 'country',\n",
       " 'market_segment',\n",
       " 'distribution_channel',\n",
       " 'reserved_room_type',\n",
       " 'assigned_room_type',\n",
       " 'deposit_type',\n",
       " 'customer_type']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols = X_train.select_dtypes(exclude='number').columns.to_list()\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    X_train[col] = X_train[col].astype('category')\n",
    "    X_online[col] = X_online[col].astype('category')\n",
    "    X_test[col] = X_test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lead_time',\n",
       " 'arrival_date_year',\n",
       " 'arrival_date_month',\n",
       " 'arrival_date_week_number',\n",
       " 'arrival_date_day_of_month',\n",
       " 'stays_in_weekend_nights',\n",
       " 'stays_in_week_nights',\n",
       " 'adults',\n",
       " 'children',\n",
       " 'babies',\n",
       " 'is_repeated_guest',\n",
       " 'previous_cancellations',\n",
       " 'previous_bookings_not_canceled',\n",
       " 'booking_changes',\n",
       " 'days_in_waiting_list',\n",
       " 'adr',\n",
       " 'required_car_parking_spaces',\n",
       " 'total_of_special_requests',\n",
       " 'hotel_Resort Hotel']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_cols = X_train.select_dtypes(exclude='category').columns.tolist()\n",
    "X_train[numeric_cols] = X_train[numeric_cols].astype(float)\n",
    "X_test[numeric_cols] = X_test[numeric_cols].astype(float)\n",
    "numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost - Test log-loss: 0.3085 | F1-weighted: 0.8660\n"
     ]
    }
   ],
   "source": [
    "name = \"CatBoost\"\n",
    "CatBoost.fit(X_train, y_train, cat_features=categorical_cols)\n",
    "proba = CatBoost.predict_proba(X_test)\n",
    "preds = np.argmax(proba, axis=1)\n",
    "loss = log_loss(y_test, proba)\n",
    "f1 = f1_score(y_test, preds, average='weighted')\n",
    "print(f\"{name} - Test log-loss: {loss:.4f} | F1-weighted: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/said/miniconda3/envs/ml_env/lib/python3.10/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM - Test log-loss: 0.3148 | F1-weighted: 0.8602\n"
     ]
    }
   ],
   "source": [
    "name = \"LGBM\"\n",
    "lgbm.fit(X_train, y_train, categorical_feature = categorical_cols)\n",
    "proba = lgbm.predict_proba(X_test)\n",
    "preds = np.argmax(proba, axis=1)\n",
    "loss = log_loss(y_test, proba)\n",
    "f1 = f1_score(y_test, preds, average='weighted')\n",
    "print(f\"{name} - Test log-loss: {loss:.4f} | F1-weighted: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'catboost': CatBoost,\n",
    "    'lgbm' : lgbm,\n",
    "    'hb' : hb\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_models: dict of trained models (XGBoost, LightGBM, CatBoost, etc.)\n",
    "# X_online, y_online: small slice for online learning\n",
    "# X_test, y_test: final test set\n",
    "\n",
    "eta = 0.5  # learning rate for exponential weighting\n",
    "n_experts = len(models)\n",
    "\n",
    "# Ensure labels are NumPy arrays for positional indexing\n",
    "y_online = np.asarray(y_online)\n",
    "y_test   = np.asarray(y_test)\n",
    "\n",
    "weights = np.ones(n_experts) / n_experts  # initial uniform weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_probas_online = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == 'hb':\n",
    "        proba = model.predict_proba(hb_online)\n",
    "    else:\n",
    "        proba = model.predict_proba(X_online)\n",
    "    expert_probas_online.append(proba)\n",
    "\n",
    "expert_probas_online = np.array(expert_probas_online)  # shape: (n_experts, n_samples, n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set log-loss: 0.30402657019077556\n",
      "Test set F1-weighted: 0.8641351183805687\n"
     ]
    }
   ],
   "source": [
    "# Collect expert predictions on test set\n",
    "expert_probas_test = []\n",
    "for name, model in models.items():\n",
    "    if name == 'hb':\n",
    "        proba = model.predict_proba(hb_test)\n",
    "    else:\n",
    "        proba = model.predict_proba(X_test)\n",
    "    expert_probas_test.append(proba)\n",
    "\n",
    "expert_probas_test = np.array(expert_probas_test)\n",
    "\n",
    "# Normalize final weights\n",
    "final_weights = weights / weights.sum()\n",
    "\n",
    "# Weighted aggregation for test set\n",
    "agg_probas_test = np.tensordot(final_weights, expert_probas_test, axes=(0, 0))  # shape (n_samples, n_classes)\n",
    "agg_preds_test = np.argmax(agg_probas_test, axis=1)\n",
    "\n",
    "# Test evaluation\n",
    "print(\"Test set log-loss:\", log_loss(y_test, agg_probas_test))\n",
    "print(\"Test set F1-weighted:\", f1_score(y_test, agg_preds_test, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    data_test[col] = data_test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set log-loss: 0.2994246203229059\n",
      "Test set F1-weighted: 0.8704161752594727\n"
     ]
    }
   ],
   "source": [
    "expert_probas_test = []\n",
    "for name, model in models.items():\n",
    "    if name == 'hb':\n",
    "        proba = model.predict_proba(hb_final_test)\n",
    "    else:\n",
    "        proba = model.predict_proba(X_test)\n",
    "    expert_probas_test.append(proba)\n",
    "\n",
    "expert_probas_test = np.array(expert_probas_test)\n",
    "# Weighted aggregation for test set\n",
    "agg_probas_test = np.tensordot(final_weights, expert_probas_test, axes=(0, 0))  # shape (n_samples, n_classes)\n",
    "agg_preds_test = np.argmax(agg_probas_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_csv('test_data.csv')['row_id']\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(f)\n",
    "res['reservation_status'] = agg_preds_test\n",
    "\n",
    "res = res.set_index('row_id')\n",
    "res.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(\"result.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
